export FLASK_APP=app
# Pick a relevant embedding model from Hugginface
export MODEL_NAME="intfloat/multilingual-e5-large"
# Max number of documents to be stored and indexed for rag
# -1 => no limit
# Here is a very low limit for testing and debugging :
export DOC_LIMIT = 10
# Max number of characters in table cells that are displayed
export TABLE_CELLS_MAXCHARS = 200
# Name of llm
export LLM="llama3.2"
# Timeout for requests to LLM
export LLM_REQ_TIMEOUT = 1200.0
# Max number of tokens in prompt
export TOKEN_LIMIT = 4000
# Path to news feeds list of URLs
export URL_LIST = "../resources/newslist.tsv"
# Path to document directory
export DOC_DIR = "../resources/documents"
# Path to vector directory
export VEC_DIR = "../resources/doc_embeddings"
# Path to concepts directory
export ENT_DOC_DIR = "../resources/entities"
# Path to umls vector directory
export ENT_VEC_DIR = "../resources/ent_embeddings"
# Do not display concepts if longer than
export MAX_LEN_FOR_CONCEPT_DESC = 500
# Max number of concepts to be proposed
export MAXNUM_DISPLAYED_CONCEPTS = 5
# Number of passages to be retrieved in DeepLake store
export SPAN_TOPK = 20
# Number of threads used during indexing
export NUM_WORKERS = 16
